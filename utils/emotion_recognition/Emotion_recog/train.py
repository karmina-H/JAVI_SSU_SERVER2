# train.py
import torch
from torch.utils.data import DataLoader
from transformers import Wav2Vec2Processor
from torch.optim import AdamW
from model import Wav2Vec2ForEmotion
from dataset import EmotionDataset

def collate_fn(batch):
    input_values = [item["input_values"] for item in batch]
    attention_mask = [item["attention_mask"] for item in batch]
    labels = torch.tensor([item["labels"] for item in batch])
    # pad sequences
    input_values = torch.nn.utils.rnn.pad_sequence(input_values, batch_first=True)
    attention_mask = torch.nn.utils.rnn.pad_sequence(attention_mask, batch_first=True)
    return {
        "input_values": input_values,
        "attention_mask": attention_mask,
        "labels": labels
    }

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ê°ì • ë¼ë²¨ ì •ì˜
label2id = {
    "Happiness": 0,
    "Surprise": 1,
    "Neutral": 2,
    "Fear": 3,
    "Disgust": 4,
    "Anger": 5,
    "Sadness": 6
}
id2label = {v: k for k, v in label2id.items()}

# Processor ë¡œë“œ
processor = Wav2Vec2Processor.from_pretrained("facebook/wav2vec2-base")

# Dataset ë¡œë“œ
dataset = EmotionDataset(
    csv_path="train.csv",
    processor=processor,
    label2id=label2id
)
dataloader = DataLoader(dataset, batch_size=8, shuffle=True, collate_fn=collate_fn)

# ëª¨ë¸ ë¡œë“œ
model = Wav2Vec2ForEmotion(num_labels=len(label2id)).to(device)

# ì˜µí‹°ë§ˆì´ì €
optimizer = AdamW(model.parameters(), lr=2e-5)

# í•™ìŠµ ë£¨í”„
for epoch in range(5):
    model.train()
    total_loss = 0

    for batch in dataloader:
        input_values = batch['input_values'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)

        outputs = model(input_values=input_values, attention_mask=attention_mask, labels=labels)
        loss = outputs['loss']

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        total_loss += loss.item()

    avg_loss = total_loss / len(dataloader)
    print(f"ğŸ“˜ Epoch {epoch+1} - í‰ê·  Loss: {avg_loss:.4f}")

# ëª¨ë¸ ì €ì¥
torch.save(model.state_dict(), "emotion_model.pt")
print("ëª¨ë¸ ì €ì¥ ì™„ë£Œ: emotion_model.pt")
