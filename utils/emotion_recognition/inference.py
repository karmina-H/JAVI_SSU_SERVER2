import torch
import torchaudio
from transformers import Wav2Vec2Processor
from model import Wav2Vec2ForEmotion

# ë¼ë²¨ ë§¤í•‘
label2id = {
    "happy": 0,
    "sad": 1,
    "angry": 2,
    "neutral": 3
}
id2label = {v: k for k, v in label2id.items()}

# ì¥ì¹˜ ì„¤ì •
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ëª¨ë¸ ë° processor ë¶ˆëŸ¬ì˜¤ê¸°
model = Wav2Vec2ForEmotion(num_labels=len(id2label))
model.load_state_dict(torch.load("emotion_model.pt", map_location=device))
model = model.to(device)
model.eval()

processor = Wav2Vec2Processor.from_pretrained("facebook/wav2vec2-base")

# ğŸ”¹ ì˜¤ë””ì˜¤ íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
filename = "input.wav"
waveform, sr = torchaudio.load(filename)

# ğŸ”¹ ìƒ˜í”Œë§ ë ˆì´íŠ¸ 16kHzë¡œ ë³€í™˜
if sr != 16000:
    resampler = torchaudio.transforms.Resample(orig_freq=sr, new_freq=16000)
    waveform = resampler(waveform)

# ğŸ”¹ ì „ì²˜ë¦¬
inputs = processor(waveform.squeeze(), sampling_rate=16000, return_tensors="pt", padding=True)
input_values = inputs["input_values"].to(device)
attention_mask = inputs.get("attention_mask", None)
if attention_mask is not None:
    attention_mask = attention_mask.to(device)

# ğŸ”¹ ì¶”ë¡ 
with torch.no_grad():
    outputs = model(input_values=input_values, attention_mask=attention_mask)
    logits = outputs['logits']
    predicted = torch.argmax(logits, dim=-1).item()

print(f"ê°ì • ì˜ˆì¸¡ ê²°ê³¼: {id2label[predicted]}")
