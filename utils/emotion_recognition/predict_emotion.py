import torch
import torchaudio
from transformers import Wav2Vec2Processor
from .model import Wav2Vec2ForEmotion  # ì‚¬ìš©ì ì •ì˜ ëª¨ë¸ í´ë˜ìŠ¤
import os
from pathlib import Path
import torch.nn.functional as F # [ì¶”ê°€] ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ ì„í¬íŠ¸

# --- 1. ì´ˆê¸° ì„¤ì • (ì´ì „ê³¼ ë™ì¼) ---

# ë¼ë²¨ ë§¤í•‘ ì •ì˜
ID2LABEL = {
    0: "Happiness",
    1: "Surprise",
    2: "Neutral",
    3: "Fear",
    4: "Disgust",
    5: "Anger",
    6: "Sadness"
}

# ì¥ì¹˜ ì„¤ì •
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {DEVICE}")

# ëª¨ë¸ ë° Processor ì „ì—­ ë³€ìˆ˜ë¡œ ë¶ˆëŸ¬ì˜¤ê¸°
try:
    print("ëª¨ë¸ê³¼ í”„ë¡œì„¸ì„œë¥¼ ë¡œë”©í•©ë‹ˆë‹¤...")
    SCRIPT_DIR = Path(__file__).resolve().parent
    MODEL_PATH = SCRIPT_DIR / "emotion_model.pt"
    
    MODEL = Wav2Vec2ForEmotion(num_labels=len(ID2LABEL))
    MODEL.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))
    MODEL.to(DEVICE)
    MODEL.eval()

    PROCESSOR = Wav2Vec2Processor.from_pretrained("facebook/wav2vec2-base")
    print("ë¡œë”© ì™„ë£Œ.")
except Exception as e:
    print(f"ì´ˆê¸°í™” ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
    MODEL = None
    PROCESSOR = None

# --- 2. ê°ì • ë¶„ì„ í•¨ìˆ˜ ---

# [ìˆ˜ì •] ë°˜í™˜ ê°’ íƒ€ì…ì„ (str, float) íŠœí”Œë¡œ ë³€ê²½
def predict_emotion(voice_path: str) -> tuple[str, float] | None:
    """
    ì£¼ì–´ì§„ ìŒì„± íŒŒì¼ ê²½ë¡œë¡œë¶€í„° ê°ì •ê³¼ í™•ë¥ ì„ ë¶„ì„í•˜ì—¬ íŠœí”Œë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.

    Args:
        voice_path (str): ë¶„ì„í•  .wav ìŒì„± íŒŒì¼ì˜ ê²½ë¡œ

    Returns:
        tuple[str, float] | None: (ê°ì • ë¬¸ìì—´, í™•ë¥  ê°’) íŠœí”Œ. ì—ëŸ¬ ì‹œ None.
    """
    if not MODEL or not PROCESSOR:
        print("ëª¨ë¸ ë˜ëŠ” í”„ë¡œì„¸ì„œê°€ ì œëŒ€ë¡œ ë¡œë”©ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return None

    if not os.path.exists(voice_path):
        print(f"ì˜¤ë¥˜: íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ - {voice_path}")
        return None

    try:
        # ... (ì˜¤ë””ì˜¤ ë¡œë”© ë° ì „ì²˜ë¦¬ ë¶€ë¶„ì€ ì´ì „ê³¼ ë™ì¼) ...
        waveform, sr = torchaudio.load(voice_path)
        if sr != 16000:
            resampler = torchaudio.transforms.Resample(orig_freq=sr, new_freq=16000)
            waveform = resampler(waveform)
        inputs = PROCESSOR(waveform.squeeze(), sampling_rate=16000, return_tensors="pt", padding=True)
        input_values = inputs["input_values"].to(DEVICE)
        attention_mask = inputs.get("attention_mask")
        if attention_mask is not None:
            attention_mask = attention_mask.to(DEVICE)
        
        # ğŸ”¹ ì¶”ë¡ 
        with torch.no_grad():
            outputs = MODEL(input_values=input_values, attention_mask=attention_mask)
            logits = outputs['logits']
            
            # [ì¶”ê°€] í™•ë¥  ê³„ì‚°
            # Softmax í•¨ìˆ˜ë¥¼ ì ìš©í•˜ì—¬ logitsë¥¼ í™•ë¥ ë¡œ ë³€í™˜
            probabilities = F.softmax(logits, dim=-1)
            
            # [ì¶”ê°€] ê°€ì¥ ë†’ì€ í™•ë¥  ê°’ê³¼ í•´ë‹¹ ì¸ë±ìŠ¤ë¥¼ ê°€ì ¸ì˜´
            confidence_score, predicted_id_tensor = torch.max(probabilities, dim=-1)
            
            predicted_id = predicted_id_tensor.item()
            highest_probability = confidence_score.item()
            
        # [ìˆ˜ì •] ê²°ê³¼ ë°˜í™˜ (ê°ì • ë ˆì´ë¸”ê³¼ í™•ë¥  ê°’ì„ í•¨ê»˜ ë°˜í™˜)
        predicted_label = ID2LABEL[predicted_id]
        return predicted_label, highest_probability

    except Exception as e:
        print(f"ê°ì • ë¶„ì„ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
        return None


# --- 3. í•¨ìˆ˜ ì‚¬ìš© ì˜ˆì‹œ ---

if __name__ == "__main__":
    # ë¶„ì„í•  ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
    audio_file = "./input.wav"
    
    # [ìˆ˜ì •] í•¨ìˆ˜ í˜¸ì¶œ ë° ë°˜í™˜ ê°’ ì²˜ë¦¬
    result = predict_emotion(audio_file)
    
    # [ìˆ˜ì •] ê²°ê³¼ ì¶œë ¥
    if result:
        # íŠœí”Œì—ì„œ ê°ì •ê³¼ í™•ë¥  ê°’ì„ ê°ê° ì¶”ì¶œ
        emotion_label, probability = result
        
        print(f"\n[ìµœì¢… ë¶„ì„ ê²°ê³¼]")
        print(f"íŒŒì¼: {audio_file}")
        print(f"ê°ì •: {emotion_label}")
        print(f"í™•ë¥ : {probability * 100:.2f}%") # ì†Œìˆ˜ì  ë‘˜ì§¸ ìë¦¬ê¹Œì§€ ë°±ë¶„ìœ¨ë¡œ í‘œì‹œ
    else:
        print("\nê°ì • ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")